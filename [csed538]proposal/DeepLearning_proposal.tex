\documentclass{article}

\usepackage[final]{neurips_2023}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors


\title{Comparative Study of GNN and CNN in Solving TSP with Good-Edge Distribution}



% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.


\author{%
Min-Gi Jo \\
20190212\\
\And
Eun-guk Cho\\
20200001\\
\And
Chan-woo Kwon \\
20210726\\
  % examples of more authors
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \AND
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
}


\begin{document}


\maketitle

\section{Problem Definition}
The Traveling Salesman Problem (TSP) is one of typical combinatorial optimization challenge. TSP can be defined as follows: given a weighted graph, find a tour with minimum total edge cost that visits every vertex exactly once. If the vertex is on a 2-dimensional plane and weight is defined as the Euclidean distance, the challenge is called 2D Euclidean TSP[1].
In our project, we use the Convolutional Neural Network (CNN) and Graph Neural Networks (GNN). CNN is a neural network that performs convolution operation and pooling, which is effective for processing structured grid data like images. GNN is a neural network designed to process graph structure. Similar to CNN, GNN performs convolution operation to find specific features.


\section{Background and Related Work}
Traditionally, methods to solve TSP have fallen into two categories: exact algorithms and heuristics. Exact algorithms[2,3], while capable of finding optimal solutions, suffer from exponential time complexity, making them impractical for large-scale problems. Heuristic approaches, such as genetic algorithms[4,5], aim to provide feasible solutions more quickly, although they sacrifice the guarantee of optimality to maintain scalability in larger instances.
Advances in deep learning have made CNNs a promising tool for tackling TSP[6]. CNNs can represent TSP instances as images, with nodes and edges depicted as pixels or grid points[7]. By training on these images, CNNs can learn a "Good-Edge Distribution"—a probability map identifying edges likely to be part of an optimal solution. This approach enables CNNs to prioritize high-likelihood edges, forming a solution path that approximates an optimal TSP tour. GNNs have emerged as a promising tool for solving TSP and other graph-based combinatorial problems by leveraging their natural ability to work with graph-structured data[8]. Through a process called message passing, GNNs propagate information across the graph, enabling them to capture both local and global structural patterns—an essential capability for effectively navigating and selecting paths in TSP.



\section{Proposed Method}
Unlike the prior paper[6] which only used CNN, our project will also apply the Good-Edge Distribution approach using GNN to perform route optimization and investigate the efficiency of results on the same instances. Thus, our project involves a cohesive process consisting of three key steps. First, we will train the optimal datasets for the TSP using both GNN and CNN approaches. Second, we will use the Good-Edge distribution from each model to compare the results with traditional algorithms for solving TSP. Third, we will analyze which deep learning model demonstrates superior performance and assess the reasons for this outcome. If successfully conducted, this project could serve as a guide for applying deep learning approaches to the TSP problem.



\newpage
\section*{References}


{
\small


[1] Lawler, E. L., Lenstra, J. K., Rinnooy Kan, A. H. G., & Shmoys, D. B. (1985). “The Traveling Salesman Problem: A Guided Tour of Combinatorial Optimization. Wiley” 
 
[2] A. Robbani, A. Latifah, D. Claudia and N. R. Syambas, "Travel Salesman Problem Algorithm Using Proposed Algorithm Development with K-Smallest City Method," 2021 7th International Conference on Wireless and Telematics (ICWT)
 
[3] Gilbert Laporte The Traveling Salesman Problem: An overview of exact and approximate algorithms
 
[4] Shujia Liu. A Powerful Genetic Algorithm for Traveling Salesman Problem. arXiv:1402.4699 [cs.NE]
 
[5] Philip Adewole, Adio Akinwale, Kehinde Otubamowo. A Genetic Algorithm for Solving Travelling Salesman Problem
 
[6]  S. Miki, D. Yamamoto and H. Ebara, "Applying Deep Learning and Reinforcement Learning to Traveling Salesman Problem," 2018 International Conference on Computing, Electronics & Communications Engineering (iCCECE), Southend, UK, 2018, pp. 65-70
 
[7] Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, Alexei A. Efros. Image-to-Image Translation with Conditional Adversarial Networks. arXiv:1611.07004 [cs.CV]
 
[8]Yimeng Min, Yiwei Bai, Carla P. Gomes. Unsupervised Learning for Solving the Travelling Salesman Problem. arXiv:2303.10538 [cs.AI].
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}